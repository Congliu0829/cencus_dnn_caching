{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Census_income.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Congliu0829/cencus_dnn_caching/blob/master/Census_income.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "da863d54-fa35-4d43-b333-7993e15bfe4a",
        "id": "5jfZbcW4VA6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%pylab inline\n",
        "import os\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import preprocessing\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "# cpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbsjzd9iGyJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import math\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# %pylab inline\n",
        "# import os\n",
        "# import time\n",
        "# from sklearn import preprocessing\n",
        "# from numpy import array\n",
        "# from numpy import argmax\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# from sklearn import preprocessing\n",
        "# from os.path import exists\n",
        "# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "# cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "# accelerator = cuda_output[1] if exists('/dev/nvidia0') else 'cpu'\n",
        "# !pip install -f https://download.pytorch.org/whl/torch_stable.html torchvision\n",
        "# cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZFLqreTWHbF",
        "colab_type": "code",
        "outputId": "45b7e313-d198-476c-f7d3-4679a76aa638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPaTj6FmmryS",
        "colab_type": "code",
        "outputId": "119df8a7-4791-4a7e-c149-bc6f3af5b743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "\n",
        "import torch\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "# !pip uninstall torch==0.4.1\n",
        "!pip install torch==0.4.1\n",
        "!pip install torchvision==0.2.2\n",
        "!pip install Pillow==6.2.2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import pickle\n",
        "from torch.utils.data.sampler import (SubsetRandomSampler,RandomSampler)\n",
        "# cpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torchvision==0.2.2 in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (6.2.2)\n",
            "Requirement already satisfied: tqdm==4.19.9 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (4.19.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (1.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (0.4.1)\n",
            "Requirement already satisfied: Pillow==6.2.2 in /usr/local/lib/python3.6/dist-packages (6.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGIcZ5DYAZtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# # http://pytorch.org/\n",
        "# from os.path import exists\n",
        "# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "# cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "# accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "# !pip install -f https://download.pytorch.org/whl/torch_stable.html torchvision\n",
        "# import torch\n",
        "# # http://pytorch.org/\n",
        "# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "# cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "# accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# from torchvision import datasets, transforms\n",
        "# from torch.utils.data import DataLoader\n",
        "# import pickle\n",
        "# from torch.utils.data.sampler import (SubsetRandomSampler,RandomSampler)\n",
        "# from torchvision import datasets, transforms\n",
        "# cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlGu9iTJtaJb",
        "colab_type": "code",
        "outputId": "17938de0-b2a9-420b-e170-8d4d08dabf67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    use_cuda = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    use_cuda = False\n",
        "    \n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbTxg6Vwtc6Y",
        "colab_type": "code",
        "outputId": "2c1827f7-95be-4bbd-ac67-891c096a81cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "full_data = pd.read_csv(\n",
        "    \"/content/adult.csv\",\n",
        "    names=[\n",
        "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
        "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
        "        \"Hours per week\", \"Country\", \"Target\"],\n",
        "        sep=r'\\s*,\\s*',\n",
        "        engine='python', skiprows=1,\n",
        "        na_values=\"?\", dtype={0:int, 1:str, 2:int, 3:str, 4:int, 5: str, 6:str , 7:str ,8:str ,9: str, 10:int, 11:int, 12:int, 13:str,14: str})\n",
        "\n",
        "print('Dataset size: ', full_data.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset size:  32561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9VeDTALt6hM",
        "colab_type": "code",
        "outputId": "b5231f11-08e7-440b-867f-374847ef65aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(full_data.head())\n",
        "print(full_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Age  Workclass  fnlwgt  ... Hours per week          Country   Target\n",
            "0   90        \"?\"   77053  ...             40  \"United-States\"  \"<=50K\"\n",
            "1   82  \"Private\"  132870  ...             18  \"United-States\"  \"<=50K\"\n",
            "2   66        \"?\"  186061  ...             40  \"United-States\"  \"<=50K\"\n",
            "3   54  \"Private\"  140359  ...             40  \"United-States\"  \"<=50K\"\n",
            "4   41  \"Private\"  264663  ...             40  \"United-States\"  \"<=50K\"\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "(32561, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JdC0nCCt9a3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str_list=[] \n",
        "for data in [full_data]:\n",
        "    for colname, colvalue in data.iteritems(): \n",
        "        if type(colvalue[1]) == str:\n",
        "            str_list.append(colname) \n",
        "num_list = data.columns.difference(str_list) #seperate str with int in input data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5AHEWt8uEK4",
        "colab_type": "code",
        "outputId": "28ac3b7d-ed24-4725-8bd5-862836c99d5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "full_size = full_data.shape[0]\n",
        "print('Dataset size Before pruning: ', full_size)\n",
        "for data in [full_data]:\n",
        "    for i in full_data:\n",
        "        data[i].replace('NaN', np.nan, inplace=True)\n",
        "    data.dropna(inplace=True)\n",
        "real_size = full_data.shape[0]\n",
        "print('Dataset size after pruning: ', real_size)\n",
        "print('We eliminated ', (full_size-real_size), ' datapoints')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset size Before pruning:  32561\n",
            "Dataset size after pruning:  32561\n",
            "We eliminated  0  datapoints\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr2T2UuJuIi6",
        "colab_type": "code",
        "outputId": "a7b042e3-97e4-4062-e9ee-c7a77d07f1e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "full_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>Education</th>\n",
              "      <th>Education-Num</th>\n",
              "      <th>Martial Status</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Relationship</th>\n",
              "      <th>Race</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Capital Gain</th>\n",
              "      <th>Capital Loss</th>\n",
              "      <th>Hours per week</th>\n",
              "      <th>Country</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90</td>\n",
              "      <td>\"?\"</td>\n",
              "      <td>77053</td>\n",
              "      <td>\"HS-grad\"</td>\n",
              "      <td>9</td>\n",
              "      <td>\"Widowed\"</td>\n",
              "      <td>\"?\"</td>\n",
              "      <td>\"Not-in-family\"</td>\n",
              "      <td>\"White\"</td>\n",
              "      <td>\"Female\"</td>\n",
              "      <td>0</td>\n",
              "      <td>4356</td>\n",
              "      <td>40</td>\n",
              "      <td>\"United-States\"</td>\n",
              "      <td>\"&lt;=50K\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>82</td>\n",
              "      <td>\"Private\"</td>\n",
              "      <td>132870</td>\n",
              "      <td>\"HS-grad\"</td>\n",
              "      <td>9</td>\n",
              "      <td>\"Widowed\"</td>\n",
              "      <td>\"Exec-managerial\"</td>\n",
              "      <td>\"Not-in-family\"</td>\n",
              "      <td>\"White\"</td>\n",
              "      <td>\"Female\"</td>\n",
              "      <td>0</td>\n",
              "      <td>4356</td>\n",
              "      <td>18</td>\n",
              "      <td>\"United-States\"</td>\n",
              "      <td>\"&lt;=50K\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>66</td>\n",
              "      <td>\"?\"</td>\n",
              "      <td>186061</td>\n",
              "      <td>\"Some-college\"</td>\n",
              "      <td>10</td>\n",
              "      <td>\"Widowed\"</td>\n",
              "      <td>\"?\"</td>\n",
              "      <td>\"Unmarried\"</td>\n",
              "      <td>\"Black\"</td>\n",
              "      <td>\"Female\"</td>\n",
              "      <td>0</td>\n",
              "      <td>4356</td>\n",
              "      <td>40</td>\n",
              "      <td>\"United-States\"</td>\n",
              "      <td>\"&lt;=50K\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54</td>\n",
              "      <td>\"Private\"</td>\n",
              "      <td>140359</td>\n",
              "      <td>\"7th-8th\"</td>\n",
              "      <td>4</td>\n",
              "      <td>\"Divorced\"</td>\n",
              "      <td>\"Machine-op-inspct\"</td>\n",
              "      <td>\"Unmarried\"</td>\n",
              "      <td>\"White\"</td>\n",
              "      <td>\"Female\"</td>\n",
              "      <td>0</td>\n",
              "      <td>3900</td>\n",
              "      <td>40</td>\n",
              "      <td>\"United-States\"</td>\n",
              "      <td>\"&lt;=50K\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>\"Private\"</td>\n",
              "      <td>264663</td>\n",
              "      <td>\"Some-college\"</td>\n",
              "      <td>10</td>\n",
              "      <td>\"Separated\"</td>\n",
              "      <td>\"Prof-specialty\"</td>\n",
              "      <td>\"Own-child\"</td>\n",
              "      <td>\"White\"</td>\n",
              "      <td>\"Female\"</td>\n",
              "      <td>0</td>\n",
              "      <td>3900</td>\n",
              "      <td>40</td>\n",
              "      <td>\"United-States\"</td>\n",
              "      <td>\"&lt;=50K\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Workclass  fnlwgt  ... Hours per week          Country   Target\n",
              "0   90        \"?\"   77053  ...             40  \"United-States\"  \"<=50K\"\n",
              "1   82  \"Private\"  132870  ...             18  \"United-States\"  \"<=50K\"\n",
              "2   66        \"?\"  186061  ...             40  \"United-States\"  \"<=50K\"\n",
              "3   54  \"Private\"  140359  ...             40  \"United-States\"  \"<=50K\"\n",
              "4   41  \"Private\"  264663  ...             40  \"United-States\"  \"<=50K\"\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8qXzXWvuKr0",
        "colab_type": "code",
        "outputId": "6971e323-7052-46d4-df87-af62fdfd55a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "full_labels = full_data['Target'].copy()\n",
        "print(full_labels.shape[0])\n",
        "\n",
        "full_data = full_data.drop(['Target'], axis=1)\n",
        "print(full_data.shape[0])\n",
        "\n",
        "# Label Encode Labels\n",
        "label_encoder = LabelEncoder()\n",
        "full_labels = label_encoder.fit_transform(full_labels)\n",
        "print(full_labels[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32561\n",
            "32561\n",
            "[0 0 0 0 0 0 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seJKmQWluOqY",
        "colab_type": "code",
        "outputId": "9e7ed1c0-f65e-4e09-a91a-2c61500b1148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "cat_data = full_data.select_dtypes(include=['object']).copy()\n",
        "other_data = full_data.select_dtypes(include=['int']).copy()\n",
        "print(cat_data.head())\n",
        "print(cat_data.shape)\n",
        "print(other_data.shape)#seperate data by objects and numbers "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Workclass       Education Martial Status  ...     Race       Sex          Country\n",
            "0        \"?\"       \"HS-grad\"      \"Widowed\"  ...  \"White\"  \"Female\"  \"United-States\"\n",
            "1  \"Private\"       \"HS-grad\"      \"Widowed\"  ...  \"White\"  \"Female\"  \"United-States\"\n",
            "2        \"?\"  \"Some-college\"      \"Widowed\"  ...  \"Black\"  \"Female\"  \"United-States\"\n",
            "3  \"Private\"       \"7th-8th\"     \"Divorced\"  ...  \"White\"  \"Female\"  \"United-States\"\n",
            "4  \"Private\"  \"Some-college\"    \"Separated\"  ...  \"White\"  \"Female\"  \"United-States\"\n",
            "\n",
            "[5 rows x 8 columns]\n",
            "(32561, 8)\n",
            "(32561, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj8LKiL1uRAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newcat_data = pd.get_dummies(cat_data, columns=[\n",
        "    \"Workclass\", \"Education\", \"Country\" ,\"Relationship\", \"Martial Status\", \"Occupation\", \"Relationship\",\n",
        "    \"Race\", \"Sex\"\n",
        "])# apply a encoder for str catagories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij2whrbvuUZp",
        "colab_type": "code",
        "outputId": "34df5e5c-7b90-4e18-ed77-6c15cc95c8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "newcat_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Workclass_\"?\"</th>\n",
              "      <th>Workclass_\"Federal-gov\"</th>\n",
              "      <th>Workclass_\"Local-gov\"</th>\n",
              "      <th>Workclass_\"Never-worked\"</th>\n",
              "      <th>Workclass_\"Private\"</th>\n",
              "      <th>Workclass_\"Self-emp-inc\"</th>\n",
              "      <th>Workclass_\"Self-emp-not-inc\"</th>\n",
              "      <th>Workclass_\"State-gov\"</th>\n",
              "      <th>Workclass_\"Without-pay\"</th>\n",
              "      <th>Education_\"10th\"</th>\n",
              "      <th>Education_\"11th\"</th>\n",
              "      <th>Education_\"12th\"</th>\n",
              "      <th>Education_\"1st-4th\"</th>\n",
              "      <th>Education_\"5th-6th\"</th>\n",
              "      <th>Education_\"7th-8th\"</th>\n",
              "      <th>Education_\"9th\"</th>\n",
              "      <th>Education_\"Assoc-acdm\"</th>\n",
              "      <th>Education_\"Assoc-voc\"</th>\n",
              "      <th>Education_\"Bachelors\"</th>\n",
              "      <th>Education_\"Doctorate\"</th>\n",
              "      <th>Education_\"HS-grad\"</th>\n",
              "      <th>Education_\"Masters\"</th>\n",
              "      <th>Education_\"Preschool\"</th>\n",
              "      <th>Education_\"Prof-school\"</th>\n",
              "      <th>Education_\"Some-college\"</th>\n",
              "      <th>Country_\"?\"</th>\n",
              "      <th>Country_\"Cambodia\"</th>\n",
              "      <th>Country_\"Canada\"</th>\n",
              "      <th>Country_\"China\"</th>\n",
              "      <th>Country_\"Columbia\"</th>\n",
              "      <th>Country_\"Cuba\"</th>\n",
              "      <th>Country_\"Dominican-Republic\"</th>\n",
              "      <th>Country_\"Ecuador\"</th>\n",
              "      <th>Country_\"El-Salvador\"</th>\n",
              "      <th>Country_\"England\"</th>\n",
              "      <th>Country_\"France\"</th>\n",
              "      <th>Country_\"Germany\"</th>\n",
              "      <th>Country_\"Greece\"</th>\n",
              "      <th>Country_\"Guatemala\"</th>\n",
              "      <th>Country_\"Haiti\"</th>\n",
              "      <th>...</th>\n",
              "      <th>Relationship_\"Not-in-family\"</th>\n",
              "      <th>Relationship_\"Other-relative\"</th>\n",
              "      <th>Relationship_\"Own-child\"</th>\n",
              "      <th>Relationship_\"Unmarried\"</th>\n",
              "      <th>Relationship_\"Wife\"</th>\n",
              "      <th>Martial Status_\"Divorced\"</th>\n",
              "      <th>Martial Status_\"Married-AF-spouse\"</th>\n",
              "      <th>Martial Status_\"Married-civ-spouse\"</th>\n",
              "      <th>Martial Status_\"Married-spouse-absent\"</th>\n",
              "      <th>Martial Status_\"Never-married\"</th>\n",
              "      <th>Martial Status_\"Separated\"</th>\n",
              "      <th>Martial Status_\"Widowed\"</th>\n",
              "      <th>Occupation_\"?\"</th>\n",
              "      <th>Occupation_\"Adm-clerical\"</th>\n",
              "      <th>Occupation_\"Armed-Forces\"</th>\n",
              "      <th>Occupation_\"Craft-repair\"</th>\n",
              "      <th>Occupation_\"Exec-managerial\"</th>\n",
              "      <th>Occupation_\"Farming-fishing\"</th>\n",
              "      <th>Occupation_\"Handlers-cleaners\"</th>\n",
              "      <th>Occupation_\"Machine-op-inspct\"</th>\n",
              "      <th>Occupation_\"Other-service\"</th>\n",
              "      <th>Occupation_\"Priv-house-serv\"</th>\n",
              "      <th>Occupation_\"Prof-specialty\"</th>\n",
              "      <th>Occupation_\"Protective-serv\"</th>\n",
              "      <th>Occupation_\"Sales\"</th>\n",
              "      <th>Occupation_\"Tech-support\"</th>\n",
              "      <th>Occupation_\"Transport-moving\"</th>\n",
              "      <th>Relationship_\"Husband\"</th>\n",
              "      <th>Relationship_\"Not-in-family\"</th>\n",
              "      <th>Relationship_\"Other-relative\"</th>\n",
              "      <th>Relationship_\"Own-child\"</th>\n",
              "      <th>Relationship_\"Unmarried\"</th>\n",
              "      <th>Relationship_\"Wife\"</th>\n",
              "      <th>Race_\"Amer-Indian-Eskimo\"</th>\n",
              "      <th>Race_\"Asian-Pac-Islander\"</th>\n",
              "      <th>Race_\"Black\"</th>\n",
              "      <th>Race_\"Other\"</th>\n",
              "      <th>Race_\"White\"</th>\n",
              "      <th>Sex_\"Female\"</th>\n",
              "      <th>Sex_\"Male\"</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 108 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Workclass_\"?\"  Workclass_\"Federal-gov\"  ...  Sex_\"Female\"  Sex_\"Male\"\n",
              "0              1                        0  ...             1           0\n",
              "1              0                        0  ...             1           0\n",
              "2              1                        0  ...             1           0\n",
              "3              0                        0  ...             1           0\n",
              "4              0                        0  ...             1           0\n",
              "\n",
              "[5 rows x 108 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vKvXxPtuWy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_data = pd.concat([other_data, newcat_data], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMYWsm6_uY1X",
        "colab_type": "code",
        "outputId": "4568d0b4-94a8-405c-97a9-c62932c9cc7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(full_data.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Age  fnlwgt  Education-Num  ...  Race_\"White\"  Sex_\"Female\"  Sex_\"Male\"\n",
            "0   90   77053              9  ...             1             1           0\n",
            "1   82  132870              9  ...             1             1           0\n",
            "2   66  186061             10  ...             0             1           0\n",
            "3   54  140359              4  ...             1             1           0\n",
            "4   41  264663             10  ...             1             1           0\n",
            "\n",
            "[5 rows x 114 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWZRJLw5ub5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = 20000\n",
        "valid_size = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InW9lsGLuefR",
        "colab_type": "code",
        "outputId": "ef4eb646-ff09-4aec-9bba-34ab4f6f54f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_x = full_data.iloc[:train_size, :]\n",
        "train_y = full_labels[:train_size]\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print()\n",
        "\n",
        "valid_x = full_data.iloc[train_size:(train_size+valid_size), :]\n",
        "valid_y = full_labels[train_size:(train_size+valid_size)]\n",
        "print(valid_x.shape)\n",
        "print(valid_y.shape)\n",
        "print()\n",
        "\n",
        "test_x = full_data.iloc[(train_size+valid_size):, :]\n",
        "test_y = full_labels[(train_size+valid_size):]\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)\n",
        "num_features = test_x.shape[1]\n",
        "print(type(train_x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 114)\n",
            "(20000,)\n",
            "\n",
            "(10000, 114)\n",
            "(10000,)\n",
            "\n",
            "(2561, 114)\n",
            "(2561,)\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_8_RqNVuho_",
        "colab_type": "code",
        "outputId": "511ca204-c29e-4446-a89d-891084bc4120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_y[:25])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP8uZn5IujjR",
        "colab_type": "code",
        "outputId": "091ab93c-5efa-4a95-bb4e-0e6421de2324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLE7X0-oulZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory = os.path.dirname('./data_ML/')\n",
        "\n",
        "try:\n",
        "    os.stat(directory)\n",
        "except:\n",
        "    os.mkdir(directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYuTnISYunlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "folder = './data_ML/'\n",
        "for the_file in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, the_file)\n",
        "    try:\n",
        "        if os.path.isfile(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "!ls \"./data_ML/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY2_lyYxuqLz",
        "colab_type": "code",
        "outputId": "623399b9-cdd2-48d3-c475-50bf58e916cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "full_dataset = np.asarray(full_data).astype(np.float32)\n",
        "z=0\n",
        "\n",
        "# load data for dataloader\n",
        "start = time.time()\n",
        "for x in range(full_dataset.shape[0]):\n",
        "    for y in range(2):\n",
        "        if full_labels[x] == y: \n",
        "            temp = (full_dataset[x,:])\n",
        "            \n",
        "            directory = './data_ML/' + str(label_encoder.classes_[y])\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            \n",
        "            \n",
        "            np.save((directory+ '/' +str(z) +'.npy'), temp)\n",
        "            \n",
        "            z += 1\n",
        "    \n",
        "end = time.time()\n",
        "\n",
        "print('Time to process: ', end-start)\n",
        "print(z, ' datapoints saved to path')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to process:  7.872073411941528\n",
            "32561  datapoints saved to path\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsINR60quzDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = np.zeros(num_features)\n",
        "std_mean = np.ones(num_features)\n",
        "\n",
        "\n",
        "class prep_stuff:\n",
        "    def __init__(self, batch_size, path):\n",
        "        self.batch_size = batch_size\n",
        "        self.path = path\n",
        "\n",
        "        batch_size_eval = 128\n",
        "          \n",
        "        self.train_data = datasets.DatasetFolder(self.path, np.load, ('npy') \n",
        "                               )\n",
        "   \n",
        "        \n",
        "        indices = list(range(len(self.train_data)))\n",
        "        random.shuffle(indices)\n",
        "\n",
        "        # Split dataset into train and Test sets\n",
        "        self.train_loader = DataLoader(\n",
        "            self.train_data,\n",
        "            batch_size=self.batch_size,\n",
        "            sampler=SubsetRandomSampler(indices[:20000]),\n",
        "            num_workers=1,\n",
        "        )\n",
        "\n",
        "        self.valid_loader = DataLoader(\n",
        "            self.train_data,\n",
        "            batch_size=self.batch_size,\n",
        "            sampler=SubsetRandomSampler(indices[20000:30000]),\n",
        "            num_workers=1,\n",
        "        )\n",
        "\n",
        "        self.test_loader = DataLoader(\n",
        "            self.train_data,\n",
        "            batch_size=batch_size_eval,\n",
        "            sampler=SubsetRandomSampler(indices[30000:]),\n",
        "            num_workers=1,\n",
        "        )\n",
        "        \n",
        "           \n",
        "\n",
        "\n",
        "# Create the object with both loader and loss functions\n",
        "\n",
        "batchSize = 1000\n",
        "# batchSize = 1\n",
        "path = './data_ML/'\n",
        "\n",
        "# 20000 for train\n",
        "# 10000 for valid \n",
        "# 2561 for Test\n",
        "pre_model = prep_stuff(batchSize, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJdp-GhVsKkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# two intermediate layers network\n",
        "class BasicNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.num_classes = num_classes\n",
        "        self.layers = 0\n",
        "        \n",
        "        self.lin1 = torch.nn.Linear(self.num_features,  150)        \n",
        "        self.lin2 = torch.nn.Linear(150, 150)        \n",
        "        self.lin3 = torch.nn.Linear(150, 150) \n",
        "        self.lin4 = torch.nn.Linear(150, self.num_classes)\n",
        "        \n",
        "        self.prelu = nn.PReLU()\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.cachelin1 = []\n",
        "        self.cachelin2 = []\n",
        "        self.cache_label = []\n",
        "\n",
        "\n",
        "\n",
        "    # def EncoderDecoder(self, xin):\n",
        "    #     dim = xin.size(1)\n",
        "    #     x = torch.nn.Linear(dim, 10)(xin)\n",
        "    #     self.cache.append(x)\n",
        "    #     x = torch.nn.Linear(10, dim)(x)\n",
        "    #     return x\n",
        "\n",
        "\n",
        "    def forward(self, xin):\n",
        "        self.layers = 0\n",
        "        x = F.relu(self.lin1(xin)) #input layer\n",
        "        #should be one cache\n",
        "        self.layers += 1\n",
        "        \n",
        "        # for y in range(8):\n",
        "        #   x = F.relu(self.lin4(x)) \n",
        "        #   self.cache.append(x)\n",
        "        #   self.layers += 1\n",
        "\n",
        "        x = F.relu(self.lin2(x))     #intermediate layer1\n",
        "        self.cachelin1.append(x)\n",
        "        \n",
        "        x = F.relu(self.lin3(x))     #intermediate layer2\n",
        "        self.cachelin2.append(x)\n",
        "\n",
        "        # x = self.dropout(x)\n",
        "        # self.cache.append(x)\n",
        "        # x = self.EncoderDecoder(x)\n",
        "        \n",
        "        x = F.relu(self.lin4(x)) #output layer\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxykNH7qvVdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    for inputs, target in train_loader:\n",
        "        inputs, target = inputs.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        loss = loss_fn(output, target)\n",
        "        # Backprop\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jn9qTo9vYRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    \n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    test_size = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      \n",
        "        for inputs, target in test_loader:\n",
        "            inputs, target = inputs.to(device), target.to(device)\n",
        "            output = model(inputs)\n",
        "            test_size += len(inputs)\n",
        "            test_loss += test_loss_fn(output, target).item() \n",
        "            pred = output.max(1, keepdim=True)[1] \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= test_size\n",
        "    accuracy = correct / test_size\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, test_size,\n",
        "        100. * accuracy))\n",
        "    \n",
        "    return test_loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEpBu3dXvaxk",
        "colab_type": "code",
        "outputId": "8ef0775b-37d3-43f5-f25c-46f4848181ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model = BasicNet(num_features, 2).to(device)\n",
        "test_accuracy = []\n",
        "train_loss = []\n",
        "nbr_epochs = 10\n",
        "lr = 0.0025\n",
        "weight_decay = 0\n",
        "\n",
        "\n",
        "# Surrogate loss used for training\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "test_loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lr ,weight_decay=weight_decay)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "print('Training beginning...')\n",
        "start_time = time.time()\n",
        "cache_input = []\n",
        "# cache_output = []\n",
        "for epoch in range(1, nbr_epochs+1):\n",
        "    print('Epoch ', epoch, ':')\n",
        "    for inputs, target in pre_model.train_loader:\n",
        "      inputs, target = inputs.to(device), target.to(device)\n",
        "      cache_input.append(inputs)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(inputs)  \n",
        "      # cache_output.append(target)\n",
        "      model.cache_label.append(target)\n",
        "      loss = loss_fn(output, target)\n",
        "      loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "    # train(model, pre_model.train_loader, optimizer, epoch)\n",
        "\n",
        "    # loss, acc = test(model, pre_model.valid_loader)\n",
        "    \n",
        "    # save results every epoch\n",
        "    \n",
        "    # test_accuracy.append(acc)\n",
        "    # train_loss.append(loss)\n",
        "    \n",
        "end_time = time.time()\n",
        "print('Training on ' + str(nbr_epochs) + ' epochs done in ', str(end_time-start_time),' seconds')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training beginning...\n",
            "Epoch  1 :\n",
            "Epoch  2 :\n",
            "Epoch  3 :\n",
            "Epoch  4 :\n",
            "Epoch  5 :\n",
            "Epoch  6 :\n",
            "Epoch  7 :\n",
            "Epoch  8 :\n",
            "Epoch  9 :\n",
            "Epoch  10 :\n",
            "Training on 10 epochs done in  52.629416704177856  seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz2Xbbcek26d",
        "colab_type": "code",
        "outputId": "15abdde6-f432-4084-e44d-b761b4c42b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# print(model.cache_label[0].size())\n",
        "print(type(model.cache_label))\n",
        "print(len(model.cache_label))\n",
        "print(model.cache_label[0].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "200\n",
            "torch.Size([1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14V7jivwcRrd",
        "colab_type": "code",
        "outputId": "e29210b1-606d-487d-e038-5309b0483c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#take out the last set of cache\n",
        "model.cache_label = model.cache_label[(len(model.cache_label)-int(train_size/batchSize)):len(model.cache_label)]\n",
        "print(len(model.cache_label))\n",
        "cachelabel = []\n",
        "for i in model.cache_label:\n",
        " cachelabel.append(i.detach().numpy())\n",
        "for i in cachelabel:\n",
        "  i.flatten()\n",
        "cache_whole_label = []\n",
        "for i in cachelabel:\n",
        "  for m in i:\n",
        "    cache_whole_label.append(m)\n",
        "########################################################cache_whole_label is whole labels of traindata"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36IRFG8TT4In",
        "colab_type": "code",
        "outputId": "343caed9-cf24-4bab-c85d-794efb4e6d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(cache_whole_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tei1J_gFMVrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 对每一个cache（一共2个）都建立一个网络来做降纬处理\n",
        "# class EncoderDecoder1(nn.Module):\n",
        "#     def __init__(self, in_dim, out_dim): \n",
        "#         super(EncoderDecoder,self).__init__()\n",
        "#         self.linear1 = torch.nn.Linear(in_dim,50) \n",
        "#         self.linear2 = torch.nn.Linear(50,50)\n",
        "#         self.linear3 = torch.nn.Linear(50,20)\n",
        "#         self.linear4 = torch.nn.Linear(20,10)\n",
        "#         self.cache_mdim = [] #New trained cache\n",
        "#         self.linear5 = torch.nn.Linear(10,out_dim)\n",
        "\n",
        "#     def forward(self,x):\n",
        "#         x = self.linear1(x)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.linear2(x)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.linear3(x)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.linear4(x)\n",
        "#         x = F.relu(x)\n",
        "#         self.cache_mdim.append(x) \n",
        "#         x = self.linear5(x)\n",
        "\n",
        "#         return x\n",
        "\n",
        "# # for i in CACHE_LIST:\n",
        "# #   i = i.view(-1,150)\n",
        "\n",
        "# coder = EncoderDecoder(150, 150).to(device)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFzsIVPAzAHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct encoder&decoder for each cache (2 in total)\n",
        "class EncoderDecoder1(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim): \n",
        "        super(EncoderDecoder1,self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(in_dim,50) \n",
        "        self.linear2 = torch.nn.Linear(50,4)\n",
        "        # self.linear3 = torch.nn.Linear(10,4)\n",
        "        # self.linear4 = torch.nn.Linear(20,10)\n",
        "        self.cache_mdim1 = [] #New trained cache\n",
        "        self.linear3 = torch.nn.Linear(4,out_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.linear1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = F.relu(x)\n",
        "        self.cache_mdim1.append(x)\n",
        "        x = self.linear3(x)\n",
        "        x = F.relu(x)\n",
        " \n",
        "        # x = self.linear4(x)\n",
        "        # x = F.relu(x)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "# for i in CACHE_LIST:\n",
        "#   i = i.view(-1,150)\n",
        "\n",
        "coder1 = EncoderDecoder1(150, 150).to(device)\n",
        "\n",
        "\n",
        "class EncoderDecoder2(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim): \n",
        "        super(EncoderDecoder2,self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(in_dim,50) \n",
        "        self.linear2 = torch.nn.Linear(50,4)\n",
        "        # self.linear3 = torch.nn.Linear(10,4)\n",
        "        # self.linear4 = torch.nn.Linear(20,10)\n",
        "        self.cache_mdim2 = [] #New trained cache\n",
        "        self.linear3 = torch.nn.Linear(4,out_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.linear1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = F.relu(x)\n",
        "        self.cache_mdim2.append(x) \n",
        "        x = self.linear3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # x = self.linear4(x)\n",
        "        # x = F.relu(x)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "# for i in CACHE_LIST:\n",
        "#   i = i.view(-1,150)\n",
        "\n",
        "coder2 = EncoderDecoder2(150, 150).to(device)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeMMTFM83AAM",
        "colab_type": "code",
        "outputId": "189a690a-43ae-4f92-e6cc-7d148be65912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "#take out the last set of original cache from basic network\n",
        "model.cachelin1 = model.cachelin1[(len(model.cachelin1)- int(train_size/batchSize)):len(model.cachelin1)]\n",
        "model.cachelin2 = model.cachelin2[(len(model.cachelin2)- int(train_size/batchSize)):len(model.cachelin2)]\n",
        "print(len(model.cachelin1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MQwWL80U8TX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert tensors in cache from basic newtork to individual tensor\n",
        "\n",
        "#convert tensors to numpy\n",
        "cachelin1_np = []\n",
        "for i in model.cachelin1:\n",
        " cachelin1_np.append(i.detach().numpy())\n",
        "for i in cachelin1_np:\n",
        "  i.flatten()\n",
        "cachelin1 = []\n",
        "for i in cachelin1_np:\n",
        "  for m in i:\n",
        "    cachelin1.append(m)\n",
        "\n",
        "\n",
        "cachelin2_np = []\n",
        "for i in model.cachelin2:\n",
        " cachelin2_np.append(i.detach().numpy())\n",
        "for i in cachelin2_np:\n",
        "  i.flatten()\n",
        "cachelin2 = []\n",
        "for i in cachelin2_np:\n",
        "  for m in i:\n",
        "    cachelin2.append(m)\n",
        "\n",
        "#convert numpy to tensors\n",
        "for i in range (len(cachelin1)):\n",
        "  cachelin1[i] = torch.from_numpy(cachelin1[i])\n",
        "\n",
        "for i in range (len(cachelin2)):\n",
        "  cachelin2[i] = torch.from_numpy(cachelin2[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIBCuSHVa7d2",
        "colab_type": "code",
        "outputId": "d0f98059-d88b-4f9e-9294-c9f0db7335b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cachelin1[0].size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([150])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfg-9kzmyN48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epoch_dim = 10\n",
        "# criterion = nn.MSELoss()\n",
        "# optimizer = optim.Adam(coder.parameters(),lr=0.01)\n",
        "# for epoch in range(epoch_dim):\n",
        "#   running_loss = 0.0\n",
        "#   for i in CACHE_LIST:\n",
        "#     for m in i:\n",
        "#       inputs = m.to(device)\n",
        "#       optimizer.zero_grad()\n",
        "#       outputs = coder(inputs)\n",
        "#       loss = criterion(outputs, inputs)\n",
        "#       loss.backward(retain_graph=True)\n",
        "#       running_loss += loss.item()\n",
        "\n",
        "\n",
        "    \n",
        "# print('Finish Training')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2gNH-aQ42ci",
        "colab_type": "code",
        "outputId": "956b2a32-2e3e-4e50-c876-d435e26cfc3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# training to reduce dimsension of first cache\n",
        "epoch_dim = 10\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(coder1.parameters(),lr=0.01)\n",
        "for epoch in range(epoch_dim):\n",
        "  running_loss = 0.0\n",
        "  for i in cachelin1:\n",
        "    inputs = i.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = coder1(inputs)\n",
        "    loss = criterion(outputs, inputs)\n",
        "    loss.backward(retain_graph=True)\n",
        "    running_loss += loss.item()\n",
        "      \n",
        "\n",
        "\n",
        "    \n",
        "print('Finish Training1')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish Training1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI0n-L5C5ACv",
        "colab_type": "code",
        "outputId": "4a232f9d-56e5-4c34-f6ef-63287f11aa32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# training to reduce dimension of second cache\n",
        "epoch_dim = 10\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(coder2.parameters(),lr=0.01)\n",
        "for epoch in range(epoch_dim):\n",
        "  running_loss = 0.0\n",
        "  for i in cachelin2:\n",
        "    inputs = i.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = coder2(inputs)\n",
        "    loss = criterion(outputs, inputs)\n",
        "    loss.backward(retain_graph=True)\n",
        "    running_loss += loss.item()\n",
        "\n",
        "\n",
        "    \n",
        "print('Finish Training2')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish Training2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekx8_APTvPXX",
        "colab_type": "code",
        "outputId": "3c03a74d-d12d-435a-d790-f531de32bbbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(coder1.cache_mdim1))\n",
        "print(len(coder2.cache_mdim2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200000\n",
            "200000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Zo-OAwhj1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#take the last set of reduced-dimension cache respectively\n",
        "cache_mdim1 = []\n",
        "cache_mdim2 = []\n",
        "cache_mdim1 = coder1.cache_mdim1[(len(coder1.cache_mdim1)-int(train_size)):len(coder1.cache_mdim1)]\n",
        "cache_mdim2 = coder2.cache_mdim2[(len(coder2.cache_mdim2)-int(train_size)):len(coder2.cache_mdim2)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWotHlk4dKFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert reduced-dimension cache to numpy for k-means respectively\n",
        "cache_mdim1_np = []\n",
        "cache_mdim2_np = []\n",
        "for i in range(len(cache_mdim1)):\n",
        "  cache_mdim1_np.append(cache_mdim1[i].detach().numpy())\n",
        "\n",
        "for i in range(len(cache_mdim2)):\n",
        "  cache_mdim2_np.append(cache_mdim2[i].detach().numpy())\n",
        "######################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGlY5w5CbsNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cache_whole_label代表总最后一组的label，cachelin1,cachelin2代表最后一组的储存的tensor，cache_mdim1和cache_midm2分别为前面的cache经过降维处理的tensor\n",
        "#cache_whole_label(list,20000,每个都是一个数字，type:<class 'numpy.int64'>), \n",
        "#cachelin1,cachelin2(list,20000,每一个都是一个tensor，torch.Size([150]))\n",
        "#cache_mdim1,cache_mdim2 (list,20000,每一个都是一个tensor,torch.Size([4]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YnmMYTmiHsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#kmeans\n",
        "# data1 = cache_mdim1_np\n",
        "# data2 = cache_mdim2_np\n",
        "# data1 = np.array(data1)\n",
        "# data2 = np.array(data2)\n",
        "# #normalization\n",
        "# def normalize(data):\n",
        "#     m = np.mean(data)\n",
        "#     mx = max(data)\n",
        "#     mn = min(data)\n",
        "#     return [(float(i) - m) / (mx - mn) for i in data]\n",
        "\n",
        "# for i in range(len(data1)):\n",
        "#   data1[i] = normalize(data1[i])\n",
        "# for i in range(len(data2)):\n",
        "#   data2[i] = normalize(data2[i])\n",
        "# from sklearn.cluster import KMeans\n",
        "# kmeans1 = KMeans(2, random_state=0).fit(data1)\n",
        "# kmeans2 = KMeans(2, random_state=0).fit(data2)\n",
        "\n",
        "\n",
        "# print(kmeans1.cluster_centers_)\n",
        "# print(kmeans2.cluster_centers_)\n",
        "# num = 0\n",
        "# for i in kmeans1.labels_:\n",
        "#   if i != 0:\n",
        "#     num = num+1\n",
        "# print(num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8oncUx6k5tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##example of kmeans from sklearn\n",
        "\n",
        "# >>> from sklearn.cluster import KMeans\n",
        "# >>> import numpy as np\n",
        "# >>> X = np.array([[1, 2], [1, 4], [1, 0],\n",
        "# ...               [4, 2], [4, 4], [4, 0]])\n",
        "# >>> kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
        "# >>> kmeans.labels_\n",
        "# array([0, 0, 0, 1, 1, 1], dtype=int32)\n",
        "# >>> kmeans.predict([[0, 0], [4, 4]])\n",
        "# array([0, 1], dtype=int32)\n",
        "# >>> kmeans.cluster_centers_\n",
        "# array([[ 1.,  2.],\n",
        "#        [ 4.,  2.]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRSHy9hlk6Oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#original cache from basic data\n",
        "cachelin1\n",
        "cachelin2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ME_F0UeLSUT",
        "colab_type": "code",
        "outputId": "964d5539-3fc7-4b7b-d948-68ae1b35dcdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(cachelin1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPC-yVHCpo9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reduced dimension cache from encoder&decoder\n",
        "cache_mdim1\n",
        "cache_mdim2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQlY73R-N3JK",
        "colab_type": "code",
        "outputId": "92547990-ff9c-4e4b-c7e8-c79adfa200df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cache_mdim1[0].size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGLoJ4MioA97",
        "colab_type": "code",
        "outputId": "43e9655c-9fc5-4c6c-9072-1ab0c87865f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(cache_mdim1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7ReQ-9Bp08Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#kmeans centroid\n",
        "# kmeans1.cluster_centers_\n",
        "# kmeans2.cluster_centers_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X52ZZysBmS9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# # from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.neighbors import NearestNeighbors\n",
        "# #核心代码\n",
        "# knn_layer1=KNeighborsClassifier(n_neighbors=10)\n",
        "# knn_layer1.fit(cache_mdim1_np,cache_whole_label)                      #用训练集进行训练模型\n",
        " \n",
        "# knn_layer2=KNeighborsClassifier(n_neighbors=10)\n",
        "# knn_layer2.fit(cache_mdim2_np,cache_whole_label)   \n",
        "\n",
        " \n",
        "#核心代码\n",
        "# prediction=knn.predict(x)\n",
        " \n",
        "# print(prediction)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSFp5pypiukH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# two intermediate layers network\n",
        "class TestNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.num_classes = num_classes\n",
        "        self.layers = 0\n",
        "        \n",
        "        self.lin1 = torch.nn.Linear(self.num_features,  150)        \n",
        "        self.lin2 = torch.nn.Linear(150, 150)        \n",
        "        self.lin3 = torch.nn.Linear(150, 150) \n",
        "        self.lin4 = torch.nn.Linear(150, self.num_classes)\n",
        "        \n",
        "        self.prelu = nn.PReLU()\n",
        "        # self.dropout = nn.Dropout(0.25)\n",
        "        self.testcachelin1 = []\n",
        "        self.testcachelin2 = []\n",
        "        self.testcache_label = []\n",
        "\n",
        "\n",
        "\n",
        "    # def EncoderDecoder(self, xin):\n",
        "    #     dim = xin.size(1)\n",
        "    #     x = torch.nn.Linear(dim, 10)(xin)\n",
        "    #     self.cache.append(x)\n",
        "    #     x = torch.nn.Linear(10, dim)(x)\n",
        "    #     return x\n",
        "\n",
        "\n",
        "    def forward(self, xin):\n",
        "        # self.layers = 0\n",
        "        x = F.relu(self.lin1(xin)) #input layer\n",
        "        #should be one cache\n",
        "        # self.layers += 1\n",
        "        \n",
        "        # for y in range(8):\n",
        "        #   x = F.relu(self.lin4(x)) \n",
        "        #   self.cache.append(x)\n",
        "        #   self.layers += 1\n",
        "\n",
        "        x = F.relu(self.lin2(x))     #intermediate layer1\n",
        "        self.testcachelin1.append(x)\n",
        "        \n",
        "        x = F.relu(self.lin3(x))     #intermediate layer2\n",
        "        self.testcachelin2.append(x)\n",
        "\n",
        "        # x = self.dropout(x)\n",
        "        # self.cache.append(x)\n",
        "        # x = self.EncoderDecoder(x)\n",
        "        \n",
        "        x = F.relu(self.lin4(x)) #output layer\n",
        "        # self.layers += 1\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibcl0WAXh51f",
        "colab_type": "code",
        "outputId": "b0d241fc-b024-409f-f150-7c76499614d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "testmodel = TestNet(num_features, 2).to(device)\n",
        "test_accuracy = []\n",
        "train_loss = []\n",
        "nbr_epochs = 10\n",
        "lr = 0.0025\n",
        "weight_decay = 0\n",
        "\n",
        "\n",
        "# Surrogate loss used for training\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "test_loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lr ,weight_decay=weight_decay)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "print('Testing beginning...')\n",
        "start_time = time.time()\n",
        "for epoch in range(1, nbr_epochs+1):\n",
        "    print('Epoch ', epoch, ':')\n",
        "    for inputs, target in pre_model.valid_loader:\n",
        "      inputs, target = inputs.to(device), target.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = testmodel(inputs)  \n",
        "      # cache_output.append(target)\n",
        "      testmodel.testcache_label.append(target)\n",
        "      loss = loss_fn(output, target)\n",
        "      loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "    # train(model, pre_model.train_loader, optimizer, epoch)\n",
        "\n",
        "    # loss, acc = test(model, pre_model.valid_loader)\n",
        "    \n",
        "    # save results every epoch\n",
        "    \n",
        "    # test_accuracy.append(acc)\n",
        "    # train_loss.append(loss)\n",
        "    \n",
        "end_time = time.time()\n",
        "print('Testing on ' + str(nbr_epochs) + ' epochs done in ', str(end_time-start_time),' seconds')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing beginning...\n",
            "Epoch  1 :\n",
            "Epoch  2 :\n",
            "Epoch  3 :\n",
            "Epoch  4 :\n",
            "Epoch  5 :\n",
            "Epoch  6 :\n",
            "Epoch  7 :\n",
            "Epoch  8 :\n",
            "Epoch  9 :\n",
            "Epoch  10 :\n",
            "Testing on 10 epochs done in  26.740750551223755  seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoTD3Ax1kDwI",
        "colab_type": "code",
        "outputId": "edea6001-c12c-4cc0-8f41-760a7021615d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(testmodel.testcache_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV5r1T2NjKO_",
        "colab_type": "code",
        "outputId": "052585e4-67ef-41cd-d157-07c2711daa77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#take out the last set of cache\n",
        "test_size = 10000\n",
        "testmodel.testcache_label = testmodel.testcache_label[(len(testmodel.testcache_label)-int(test_size/batchSize)):len(testmodel.testcache_label)]\n",
        "print(len(testmodel.testcache_label))\n",
        "testcachelabel = []\n",
        "for i in testmodel.testcache_label:\n",
        " testcachelabel.append(i.detach().numpy())\n",
        "for i in testcachelabel:\n",
        "  i.flatten()\n",
        "testcache_whole_label = []\n",
        "for i in testcachelabel:\n",
        "  for m in i:\n",
        "    testcache_whole_label.append(m)\n",
        "########################################################cache_whole_label is whole labels of traindata"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qv7jpiA_PaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct encoder&decoder for each cache (2 in total)\n",
        "class testEncoderDecoder1(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim): \n",
        "        super(testEncoderDecoder1,self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(in_dim,50) \n",
        "        self.linear2 = torch.nn.Linear(50,4)\n",
        "        # self.linear3 = torch.nn.Linear(10,4)\n",
        "        # self.linear4 = torch.nn.Linear(20,10)\n",
        "        self.testcache_mdim1 = [] #New trained cache\n",
        "        self.linear3 = torch.nn.Linear(4,out_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.linear1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = F.relu(x)\n",
        "        self.testcache_mdim1.append(x)\n",
        "        x = self.linear3(x)\n",
        "        x = F.relu(x)\n",
        " \n",
        "        # x = self.linear4(x)\n",
        "        # x = F.relu(x)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "# for i in CACHE_LIST:\n",
        "#   i = i.view(-1,150)\n",
        "\n",
        "testcoder1 = testEncoderDecoder1(150, 150).to(device)\n",
        "\n",
        "\n",
        "class testEncoderDecoder2(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim): \n",
        "        super(testEncoderDecoder2,self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(in_dim,50) \n",
        "        self.linear2 = torch.nn.Linear(50,4)\n",
        "        # self.linear3 = torch.nn.Linear(10,4)\n",
        "        # self.linear4 = torch.nn.Linear(20,10)\n",
        "        self.testcache_mdim2 = [] #New trained cache\n",
        "        self.linear3 = torch.nn.Linear(4,out_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.linear1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = F.relu(x)\n",
        "        self.testcache_mdim2.append(x) \n",
        "        x = self.linear3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # x = self.linear4(x)\n",
        "        # x = F.relu(x)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "# for i in CACHE_LIST:\n",
        "#   i = i.view(-1,150)\n",
        "\n",
        "testcoder2 = testEncoderDecoder2(150, 150).to(device)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfUHxGB2_Sxd",
        "colab_type": "code",
        "outputId": "4bf1323c-e1d8-43bc-88b9-c92c6c0e4176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#take out the last set of original cache from basic network\n",
        "testmodel.testcachelin1 = testmodel.testcachelin1[(len(testmodel.testcachelin1)- int(test_size/batchSize)):len(testmodel.testcachelin1)]\n",
        "testmodel.testcachelin2 = testmodel.testcachelin2[(len(testmodel.testcachelin2)- int(test_size/batchSize)):len(testmodel.testcachelin2)]\n",
        "print(len(testmodel.testcachelin1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMCJui2xAlgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert tensors in cache from basic newtork to individual tensor\n",
        "\n",
        "#convert tensors to numpy\n",
        "testcachelin1_np = []\n",
        "for i in testmodel.testcachelin1:\n",
        " testcachelin1_np.append(i.detach().numpy())\n",
        "for i in testcachelin1_np:\n",
        "  i.flatten()\n",
        "testcachelin1 = []\n",
        "for i in testcachelin1_np:\n",
        "  for m in i:\n",
        "    testcachelin1.append(m)\n",
        "\n",
        "\n",
        "testcachelin2_np = []\n",
        "for i in testmodel.testcachelin2:\n",
        " testcachelin2_np.append(i.detach().numpy())\n",
        "for i in testcachelin2_np:\n",
        "  i.flatten()\n",
        "testcachelin2 = []\n",
        "for i in testcachelin2_np:\n",
        "  for m in i:\n",
        "    testcachelin2.append(m)\n",
        "\n",
        "#convert numpy to tensors\n",
        "for i in range (len(testcachelin1)):\n",
        "  testcachelin1[i] = torch.from_numpy(testcachelin1[i])\n",
        "\n",
        "for i in range (len(testcachelin2)):\n",
        "  testcachelin2[i] = torch.from_numpy(testcachelin2[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu4iaoQGBlEx",
        "colab_type": "code",
        "outputId": "dbf078a8-a467-4790-a80b-808458af5457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# training to reduce dimsension of first cache\n",
        "epoch_dim = 10\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(testcoder1.parameters(),lr=0.01)\n",
        "for epoch in range(epoch_dim):\n",
        "  running_loss = 0.0\n",
        "  for i in testcachelin1:\n",
        "    inputs = i.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = testcoder1(inputs)\n",
        "    loss = criterion(outputs, inputs)\n",
        "    loss.backward(retain_graph=True)\n",
        "    running_loss += loss.item()\n",
        "      \n",
        "\n",
        "\n",
        "    \n",
        "print('Finish Training test 1')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish Training test 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB1C8gYdBqop",
        "colab_type": "code",
        "outputId": "d4b86a69-9e0e-49ee-aa4e-2aab4eb86f35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# training to reduce dimsension of first cache\n",
        "epoch_dim = 10\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(testcoder2.parameters(),lr=0.01)\n",
        "for epoch in range(epoch_dim):\n",
        "  running_loss = 0.0\n",
        "  for i in testcachelin2:\n",
        "    inputs = i.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = testcoder2(inputs)\n",
        "    loss = criterion(outputs, inputs)\n",
        "    loss.backward(retain_graph=True)\n",
        "    running_loss += loss.item()\n",
        "      \n",
        "\n",
        "\n",
        "    \n",
        "print('Finish Training test 2')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish Training test 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmO6ceEXB4DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#take the last set of reduced-dimension cache respectively\n",
        "testcache_mdim1 = []\n",
        "testcache_mdim2 = []\n",
        "testcache_mdim1 = testcoder1.testcache_mdim1[(len(testcoder1.testcache_mdim1)-int(test_size)):len(testcoder1.testcache_mdim1)]\n",
        "testcache_mdim2 = testcoder2.testcache_mdim2[(len(testcoder2.testcache_mdim2)-int(test_size)):len(testcoder2.testcache_mdim2)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdzvLdctQ3dI",
        "colab_type": "code",
        "outputId": "375fb94d-dda2-4562-db83-219f9cf23fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testcache_mdim1[0].size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRaP2NVICYF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert reduced-dimension testcache to numpy \n",
        "testcache_mdim1_np = []\n",
        "testcache_mdim2_np = []\n",
        "for i in range(len(testcache_mdim1)):\n",
        "  testcache_mdim1_np.append(testcache_mdim1[i].detach().numpy())\n",
        "\n",
        "for i in range(len(testcache_mdim2)):\n",
        "  testcache_mdim2_np.append(testcache_mdim2[i].detach().numpy())\n",
        "######################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmeBLJF_FTT2",
        "colab_type": "code",
        "outputId": "5031e855-2c7f-4038-cbe0-409c5ff21e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(testcache_mdim2_np[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG54mwDSvuQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalization\n",
        "\n",
        "def normalize(data):\n",
        "    m = np.mean(data)\n",
        "    mx = max(data)\n",
        "    mn = min(data)\n",
        "    return [(float(i) - m) / (mx - mn) for i in data]\n",
        "\n",
        "\n",
        "for i in range(len(cache_mdim1_np)):\n",
        "  cache_mdim1_np[i] = normalize(cache_mdim1_np[i])\n",
        "\n",
        "for i in range(len(cache_mdim2_np)):\n",
        "  cache_mdim2_np[i] = normalize(cache_mdim2_np[i])\n",
        "\n",
        "for i in range(len(testcache_mdim1_np)):\n",
        "   testcache_mdim2_np[i] = normalize(testcache_mdim2_np[i])\n",
        "\n",
        "for i in range(len(testcache_mdim2_np)):\n",
        "   testcache_mdim1_np[i] = normalize(testcache_mdim1_np[i])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH_VbyLtEoUn",
        "colab_type": "code",
        "outputId": "af9a9853-8844-4628-94a7-5f303da27273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(cache_mdim2_np[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.25, 0.75, -0.25, -0.25]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tFnigV06-ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cache_mdim2_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDPq3TVhpPkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "neigh_layer1 = NearestNeighbors(n_neighbors=5)\n",
        "neigh_layer1.fit(cache_mdim1_np) #训练第一层的cache，是个预测模型\n",
        "neigh_layer1_list = []\n",
        "for i in range(len(testcache_mdim1_np)):\n",
        "  neigh_layer1_list.append(neigh_layer1.kneighbors([testcache_mdim1_np[i]]))\n",
        "\n",
        "\n",
        "\n",
        "# neigh_layer1_list的长度应该是10000，每一个里面有2个元素，前者是对应于五个最近邻居的距离，后五个对应邻居的索引"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjsZ6D8QBIEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neigh_layer1_list[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plWf_KrBGXua",
        "colab_type": "code",
        "outputId": "e7f1a1e3-7769-4da3-c119-6ba723b92c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "times0 = 0\n",
        "times1 = 0\n",
        "list_confidence0 = []\n",
        "list_confidence1 = []\n",
        "distance0 = 0\n",
        "distance1 = 0\n",
        "#initialize\n",
        "for i in range(len(neigh_layer1_list)):\n",
        "  for j in range(5):\n",
        "    if cache_whole_label[neigh_layer1_list[i][1][0][j]] == 1:\n",
        "       times1 = times1 + 1\n",
        "       distance1 = distance1 + 1/neigh_layer1_list[i][0][0][j]\n",
        "    if cache_whole_label[neigh_layer1_list[i][1][0][j]] == 0:\n",
        "       times0 = times0 + 1\n",
        "       distance0 = distance0 + 1/neigh_layer1_list[i][0][0][j]\n",
        "  confidence0 = times0/5*distance0\n",
        "  confidence1 = times1/5*distance1\n",
        "  list_confidence0.append(confidence0)\n",
        "  list_confidence1.append(confidence1)\n",
        "  #delete to 0\n",
        "  confidence0 = 0\n",
        "  confidence1 = 0\n",
        "  distance0 = 0\n",
        "  distance1 = 0\n",
        "  times0 = 0\n",
        "  times1 = 0\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDdZ4fzAFCTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "con_label = []\n",
        "for i in range(len(list_confidence0)):\n",
        "  if list_confidence0[i] > list_confidence1[i]:\n",
        "    con_label.append([list_confidence0[i],\"0\"])\n",
        "  if list_confidence0[i] < list_confidence1[i]:\n",
        "    con_label.append([list_confidence1[i],\"1\"])\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cozb5c7FH7Ie",
        "colab_type": "code",
        "outputId": "b741e037-c4e3-453d-fe69-69a08ff2a66f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(con_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSKoRuf0hnJ0",
        "colab_type": "code",
        "outputId": "34292bb3-eab9-487b-8671-e27242d9e151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "con_label[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.974836812686197, '1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}